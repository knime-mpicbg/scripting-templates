########################################################################################
# name: Get gene info from NCBI
# author: Martin Stoeter
# category: bioinformatics
# preview: 

Gets the gene name, symbol, NewlocusID, CurrentRecord, LastUpdate, locusID, and species from NCBI data base

Output: table from NCBI

NOTE: requires R-library NCBI2R
######

<rgg>

<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->

<separator label="Options" span="full"/>
<gaprow height="2"/>

#1.0 Parameter selection

<group>
# 1) select the column for gene IDs

geneIDcolumn = <combobox items="$$$NUM_ATTRIBUTES$$$" label="Gene ID"/>

</group>

<![CDATA[

#2.0 R code

#2.1 load libraries
library(NCBI2R)

#2.2.1 manage RGG to R: define as numbers

#2.2.2 manage RGG to R: set values to default and check values
##geneIDs <- kIn[which(!is.na(kIn[,geneIDcolumn])),geneIDcolumn]
geneIDs <- as.numeric(levels(factor(kIn[,geneIDcolumn])))   ##removes NA, groups same geneIDs, converts to number (here, still could be a double!)

#2.3. calulate

ncbiTable <- GetGeneNames(geneIDs)
rOut <- ncbiTable

]]>

</rgg>
#######################################################################################
# name: Calculate percent responders (2:1, for ArrayScan cell data)
# author: Martin Stoeter
# category: calculators
# preview: 

Calculates percent "HIGH" and "LOW" similarly as ArrayScan BioApplications. Using an upper and lower threshold value objects/cells will be classified as above or below these thresholds and percentages of all objects within a well will be calculated. This will be done for all wells and all parameters (use loop for multiple plates).

THIS SNIPPET EXPECTS TWO TABLES: OBJECT/CELL DATA and A TABLE WITH THRESHOLDS PER PARAMETER:
Top input (object/cell data):
- select columns for row and column information
Bottom input (parameter-threshold table):
- select columns that contain parameter names 
- select columns that contain upper and lower thresholds

Hint: generate bottom table by aggregation of reference data (e.g. negative control) as mean/median and sd of each parameter, use math node to calculate upper and lower threshold from these values (e.g. mean +/- 2xsd).

ATTENTION: NEEDS 2:1 SNIPPET!!!
######
<rgg>
<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->
<separator label="Options top table (object/cell data)" span="full"/>
<gaprow height="2"/>

#1.0 Parameter selection
<group>
# 1.1 select row and column data
<hbox>
rowName = <combobox items="$$$ALL_ATTRIBUTES$$$" label="Row:" default-value="plateRow"/>;
colName = <combobox items="$$$ALL_ATTRIBUTES$$$" label="Column:" default-value="plateColumn"/>;
</hbox>

<gaprow height="1"/>
<separator label="Options bottom table (parameter-threshold table)" span="full"/>
<gaprow height="2"/>

# 1.2 select parameter column
parameterColumn = <combobox items="$$$ALL_ATTRIBUTES_2$$$" label="Parameter:"/>;

# 1.3 select threshold columns
<hbox>
thrHigh = <combobox items="$$$NUM_ATTRIBUTES_2$$$" label="Upper threshold:"/>;
thrLow = <combobox items="$$$NUM_ATTRIBUTES_2$$$" label="Lower threshold:"/>;
</hbox>

</group>

<![CDATA[

#2.0 R code
#parameterColumn <- "parameterName"
#thrHigh <- "high"
#thrLow <- "low"
#rowName <- "plateRow"
#colName <- "plateColumn"

#2.1 load libraries

#2.2.1 manage RGG to R: define as numbers

#2.2.2 manage RGG to R: set values to default and check values

#2.3. calulate
wellList <- list()
wellID <- 1

#iterate over rows
rowVec <- unique(kIn1[,rowName])
for (row in rowVec){
	subdataRow <- kIn1[which(kIn1[,rowName] == row),]
	#iterate over columns
	colVec <- unique(subdataRow[,colName])
	for (col in colVec){
		subdataCol <- subdataRow[which(subdataRow[,colName] == col),]
		#iterate over all parameters
		for (currentParameter in kIn2[,parameterColumn]){
			percentLow <- length(which(subdataCol[,currentParameter] < kIn2[which(kIn2[,parameterColumn] == currentParameter),thrLow])) / length(na.omit(subdataCol[,currentParameter])) * 100
			percentHigh <- length(which(subdataCol[,currentParameter] > kIn2[which(kIn2[,parameterColumn] == currentParameter),thrHigh])) / length(na.omit(subdataCol[,currentParameter])) * 100
			wellList[[wellID]] <- data.frame("parameter" = currentParameter, "plateRow" = row, "plateColumn" = col, "percentHigh" = percentHigh, "percentLow" = percentLow)
			wellID <- wellID +1
			}
		}
	}
rOut <- data.frame(do.call("rbind", wellList))

]]>
</rgg>
########################################################################################
# name: Median and MAD
# author: Marc Bickle
# category: calculators

Calculates the median and the median absolute deviation (MAD) of the specified parameters grouped by the specified metadata column.

######
<rgg>

<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->

<separator label="Options" span="full"/>
<gaprow height="2"/>

#1.0 Parameter selection
<group>
selReadouts = c(<panellistbox label="Parameters of interest" items="$$$NUM_ATTRIBUTES$$$" span="full"/>)
Group = c(<panellistbox label="Grouping column" items="$$$STR_ATTRIBUTES$$$" span="full"/>)
</group>

<![CDATA[
#2.0 R code

#2.3. calulate
ret<-lapply(selReadouts, function(param){
	mads<-tapply(kIn[,param], kIn[,Group], mad)
	meds<-tapply(kIn[,param], kIn[,Group], median)
	medmad<-data.frame(meds,mads)
	names(medmad)<-paste(param,c("(median)","(MAD)"), sep=" ")
	medmad
});

kIn<-do.call("cbind",ret);
kIn<-cbind(kIn, rownames(kIn))

rOut <- kIn;

]]>
</rgg>
########################################################################################
# name: R math / absolute values
# author: Martin Stoeter
# category: calculators

Calculates absolute values of selected columns. Useful for turning a correlation matrix (e.g. Linear Correlation) containing correlation and anti-correlation into a matrix containing absolute correlation values (anti-correlation = correlation)
- select columns to be returned as absolute values. Not selected columns will be returned as they are.
- select if values should be returned as 1-absolute(value), useful for hierarchical clustering, where highly correlating parameters should show low distance (therefore cluster together).
Available formulars: a) abs(x), b) 1-abs(x)
######
<rgg>

<!--1. Title and short description -->
<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->
<separator label="Options" span="full"/>
<gaprow height="2"/>

#1.0 Parameter selection
<group>
# 1) select the columns
parameters = match(c(<panellistbox label="Column selection" items="$$$NUM_ATTRIBUTES$$$" visible-row-count="6" span="full"/>), names(kIn));

# 2) select math
mathForm = c(<combobox label="Mathematical formula" items="absolute_values,1-absolute_values"/>)
</group>

<![CDATA[

#2.0 R code

#2.1 load libraries

#2.2.1 manage RGG to R: define as numbers

#2.2.2 manage RGG to R: set values to default and check values

#2.3. calulate
if (mathForm == "absolute_values"){
	for (parameter in parameters){
		kIn[,parameter] <- abs(kIn[,parameter])
		}
	}

if (mathForm == "1-absolute_values"){
	for (parameter in parameters){
		kIn[,parameter] <- 1-abs(kIn[,parameter])
		}
	}

rOut <- kIn

]]>
</rgg>

########################################################################################
# name: Unique values
# author: Antje Niederlein
# category: calculators

Returns unique values for all selected columns independently. If they differ in length, missing values will be added.

######

<rgg>

<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>


<!-- 2. Configuration-->

<separator label="Options" span="full"/>
<gaprow height="2"/>

# 1. Parameter selection

<group>
# 1) select the columns
colSelection = match(c(<panellistbox label="Column selection" items="$$$ALL_ATTRIBUTES$$$" visible-row-count="6" span="full"/>), names(kIn));

</group>


<![CDATA[

plist <- lapply(kIn[,colSelection], unique)

maxlen<- max(sapply(plist, length))

new.l <- lapply(plist, FUN = function(elem) {  c(elem,rep(NA,maxlen-length(elem))) })

rOut <- data.frame(do.call("cbind", new.l))

]]>

</rgg>
########################################################################################
# name: Mahalanobis Distance Calculator
# category: distance measures

Calculates mahalonobis distances to the mean of a control group (typically your negative controls). 
Option: choose to use the inverted covariance matrix (default: auto) 
ATTENTION: this snippet expects a column named 'treatment' with categorial values! 
######
<rgg>

<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->

<separator label="Options" span="full"/>
<gaprow height="2"/>

#1.0 Parameter selection

<group>
# 1) select the readouts that span the phenotypic space
featSelection = match(c(<panellistbox label="Features of interest" items="$$$NUM_ATTRIBUTES$$$" visible-row-count="6" span="full"/>), names(kIn));

# 2) calculate mean and covariance of the negative controls
negCtrls = subset(kIn, treatment == <combobox items="$$$DOMAIN('treatment')$$$" label="Negative Control"/>);

useInverted = <combobox label="use inverted" items="auto,false,true"/>
</group>

<![CDATA[
#2.0 R code

#2.1 load libraries
library(MASS)

#2.2.1 manage RGG to R: define as numbers

#2.2.2 manage RGG to R: set values to default and check values

#2.3. calulate
nc <- negCtrls[,featSelection]
ncCov <- cov(na.omit(array(nc)))
ncMean <- colMeans(nc, na.rm=TRUE)
outInverted <- useInverted

#check the determinant of the covariance matrix to prevent error message if determinant is too small
if(useInverted == "auto") {
	if(det(ncCov) < .Machine$double.eps) {
		#if too small take inverse matrix
		useInverted <- "true"
	}
	else useInverted <- "false"
}
if(useInverted == "true") {
	#if too small take inverse matrix
	ncCov <- ginv(ncCov)
	mahaInverted <- TRUE
} 
if(useInverted == "false") {
	ncCov <- cov(na.omit(array(nc)))
	mahaInverted <- FALSE
}

# append the distance as additional column
kIn$mahadist <- mahalanobis(array(kIn[featSelection]), ncMean, ncCov, inverted = mahaInverted);
kIn$mahadistMode <- outInverted

rOut <- kIn;

]]>
</rgg>
######################################################################################
# name: Power transformation and Z rank transformation
# author: Martin Stoeter, Caroline Reiche
# category: distributions
# preview: 

This rank-preserving data transformation is a pre-processing technique to stabilize the variance and to make the data more normal distribution-like. The Z rank transformation (project_to_Gaussian) projects the data to a random normal distribution. For each group and each parameter the values are transformed independently.
- select type of normalization
- select parameters that should be rank normalized 
- select a group column that should be used for ranking (e.g. barcode, date, project name,...)
If subset data is chosen as reference, only this subset data is used to calculate the lambda for the transformation (either a) or b); not possible in Z rank!).
a) select a column and give name of subset data used as reference 
b) select subset of column 'treatment' to be used as reference (needs a column with name 'treatment') 
######

<rgg>
<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->
<separator label="Options" span="full"/>
<gaprow height="2"/>

#1.0 Parameter selection
<group>
# 1.1 select type of transformation
transformation = <combobox items="Box-Cox,Yeo-Johnson,basic,project_to_Gaussian" label="Power transformation"/>;

# 1.2 select the columns
selectedParams = match(c(<panellistbox label="Column selection" items="$$$NUM_ATTRIBUTES$$$" visible-row-count="6" span="full"/>), names(kIn));

# 1.3 select group
group = <combobox items="$$$STR_ATTRIBUTES$$$" label="Group column"/>

# 1.4 select subset
<separator label="Subset data as reference" span="full"/>
subsetOption = <combobox items="-NO SUBSET - USE ALL DATA IN GROUP!-,a) subset column,b) subset of column 'treatment'" label="Subset column"/>
<hbox>
subsetColumn = <combobox items="-NOT USED-,$$$STR_ATTRIBUTES$$$" label="a) Subset column"/>
<textfield label="subset:" var="subsetName" data-type="text" default-value= "" size="5" />
</hbox>
subsetTreatment = <combobox label="b) Subset of column 'treatment'" items="-NOT USED-,$$$DOMAIN('treatment')$$$" />

</group>

<![CDATA[

#2.0 R code

#2.1 load libraries
library(car)
library(alr3)

#2.2.1 manage RGG to R: define as numbers

#2.2.2 manage RGG to R: set values to default and check values

#2.3. calulate

data <-kIn
allGroups <- unique(data[,group])


if (transformation == "project_to_Gaussian") {

	#calc max number of values per group
	maxNumberOfValues <- list()
	for (i in 1:(length(allGroups))) {
		maxNumberOfValues[[i]] <- data.frame(columnName = allGroups[i], values = length(which(data[,group] == allGroups[i]))) 
		}
	maxNumberOfValues <- do.call("rbind", maxNumberOfValues) 

	#calc z rank normalization per group
	for (i in 1:(length(allGroups))) {	
		#generate normal distributes data (100-fold resolution of number of value in group)
		normData <- sort(rnorm((maxNumberOfValues[i, "values"]+1)*100, mean = 0, sd = 1))	
	
		for (param in 1:(length(selectedParams))) {
			#replace raw values with projected raw data to normal distribution
			temp <- data.frame(rowID = which(data[,group] == allGroups[i]), values = data[which(data[,group] == allGroups[i]), selectedParams[param]], rank = as.integer(rank(data[which(data[,group] == allGroups[i]), selectedParams[param]])), normData = normData[as.integer(rank(data[which(data[,group] == allGroups[i]), selectedParams[param]]))*100+50])
			data[temp[,"rowID"], selectedParams[param]] <- temp[,"normData"] 
			}
		}
		transformedNames <- paste(names(data)[selectedParams], '.zrank', sep = "") #project_to_Gaussian	

	} else {
	
	if ((transformation == "Box-Cox") | (transformation == "basic")) {
	
		#ensure that all values are strictly positive
		for (j in 1:length(selectedParams)) {
			param <- selectedParams[j]
			data[, param] <- data[, param] - min(data[, param]) + 0.01
			}
		}

	for (i in 1:(length(allGroups))) {	
		# calculate the optimal lambda for the trafo
		switch(which(subsetOption == c("-NO SUBSET - USE ALL DATA IN GROUP!-","a) subset column","b) subset of column 'treatment'")), {
			#all data
			dataMatrix <- as.matrix(data[which(data[,group] == allGroups[i]), selectedParams]) 
			}, {
			#a) subset column
			if (subsetColumn != "-NOT USED-") {
				dataMatrix <- as.matrix(data[which((data[,group] == allGroups[i]) & (data[, subsetColumn] == subsetName)), selectedParams])
				} else {
				dataMatrix <- as.matrix(NA)	
				}
			}, { 
			#b) 'treatment'
			if (subsetTreatment != "-NOT USED-") {
				dataMatrix <- as.matrix(data[which((data[,group] == allGroups[i]) & (data[,"treatment"] == subsetTreatment)), selectedParams])
				} else {
				dataMatrix <- as.matrix(NA)	
				}
			})

		if (length(dataMatrix) > 2) {
			
			# apply the trafo
			switch(which(transformation == c('Box-Cox','Yeo-Johnson','basic')), {

				powers <- c()
				for (k in 1:ncol(dataMatrix)) {
					powers[k] <- powerTransform(dataMatrix[,k])$lambda
					}
				data[which(data[,group] == allGroups[i]), selectedParams] <- bcPower(data[which(data[,group] == allGroups[i]), selectedParams], powers) #Box-Cox
				transformedNames <- paste(names(data)[selectedParams], '.bcPower', sep = "")}, { 

				powers <- c()
				for (k in 1:ncol(dataMatrix)) {
					powers[k] <- powerTransform(dataMatrix[,k],family="yjPower")$lambda
					}
				data[which(data[,group] == allGroups[i]), selectedParams] <- yjPower(data[which(data[,group] == allGroups[i]), selectedParams], powers) #Yeo-Johnson
				transformedNames <- paste(names(data)[selectedParams], '.yjPower', sep = "")}, { 

				powers <- c()
				for (k in 1:ncol(dataMatrix)) {
					powers[k] <- powerTransform(dataMatrix[,k])$lambda
					}
				data[which(data[,group] == allGroups[i]), selectedParams] <- basicPower(data[which(data[,group] == allGroups[i]), selectedParams], powers) #basic power transformation
				transformedNames <- paste(names(data)[selectedParams], '.power', sep = "")})
			
			} else {
			data[which(data[,group] == allGroups[i]), selectedParams] <- NA	
			}
		}
	}
	
#rename transformed data columns
#switch(which(transformation == c('Box-Cox','Yeo-Johnson','basic','project_to_Gaussian')), {
#	transformedNames <- paste(names(data)[selectedParams], '.bcPower', sep = "")}, { #Box-Cox#
#	transformedNames <- paste(names(data)[selectedParams], '.yjPower', sep = "")}, { #Yeo-Johnson
#	transformedNames <- paste(names(data)[selectedParams], '.power', sep = "")}, { #basic power transformation
#	transformedNames <- paste(names(data)[selectedParams], '.zrank', sep = "")} #project_to_Gaussian
#	)
	
# bind both dataframes together	
newColNames <- c(names(kIn), transformedNames)
rOut <- cbind(kIn, data[,selectedParams])	
names(rOut) <- newColNames	

]]>
</rgg>
########################################################################################
# name: Ranking Multiparametric Profiles (for Normalization Carpenter)
# author: Marc Bickle
# category: distributions

Ranks the values of a parameter in a multi parametric profile within a dataset. Best practice is to use normalised data and rank over the entire data set.
######
<rgg>

<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->

<separator label="Options" span="full"/>
<gaprow height="2"/>

#1. Parameter selection
<group>
selReadouts = c(<panellistbox label="Parameters to normalize" items="$$$NUM_ATTRIBUTES$$$" span="full"/>)
Dataset = c(<panellistbox label="Choose the datasets" items="$$$STR_ATTRIBUTES$$$" span="full"/>);
</group>

<![CDATA[
#2.0 R code

#2.3. calulate
setList <- unique(kIn[,Dataset])
final<-NULL
for (j in 1:length(setList)){
	data <- kIn[which(kIn[,Dataset] == setList[j]),]
	res<- data
	for (i in 1:length(selReadouts)) {
  		#DEBUG i<- 3
  		rankData<- rank(data[,selReadouts[i]])
  		rankData<-data.frame(rankData)
  		names(rankData)<-paste(names(kIn[selReadouts[i]]), "rank", sep ="_")
  		res<-cbind(res,rankData)
		}
	final <- rbind(final,res)
	}

rOut <- final;

]]>
</rgg>
########################################################################################
# name: Shapiro-Wilk Normality Test (QQ-Plot)
# author: Holger Brandl, Martin Stoeter 
# category: distributions
# preview: qq-plot.png

Shapiro-Wilk Normality Test calculates statistics to judge the distribution of data (with respect to normal distribution). 
The QQ-Plot visualizes the data in respect to a normal distribution. 
- to use a flow variable check box and type in variable name using the format: FLOWVAR(variable name)
- use the R-plot template "QQ-Plot grid" to do the QQ-plots
######

<rgg>

<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->

<separator label="Options" span="full"/>
<gaprow height="2"/>

#1. Parameter selection
<group>

#Select the parameter of interest
<label text="Select your parameters for which you would like to do the Shapiro-Wilk Normality Test"/>

selReadouts = c(<panellistbox label="Parameters of interest" items="$$$NUM_ATTRIBUTES$$$" span="full"/>)
<hbox>
<checkbox  label="use flow variable" var="useFlowVarSelReadouts" selected="false"/>
<textfield label="flow variable:" var="flowVariableSelReadouts" data-type="text" default-value= "" size="10" span="full"/>
</hbox>

</group>

<![CDATA[

#2. r-code

#2.0 load libaries

#2.1 manage RGG to R: define as numbers

#2.2 manage RGG to R: set scales to default and check scales
if (useFlowVarSelReadouts) selReadouts <- flowVariableSelReadouts

#3. calulate
#allResults <- list()
# iterate over all parameters and create plots for all of them
#ret <- apply(selReadouts, FUN = function (param) {
#	plotVar = eval(parse(text = paste("kIn$\"", param, "\"", sep = '')))
	#remove NA (shaper test allows only maximum of 5000 NA)
#	plotVar <- plotVar[which(!is.na(plotVar))]

	# do the test and add the p-value to the plot
#	testresult <- shapiro.test(plotVar)
#	ShapiroResults <- data.frame(parameter = param, pvalue = testresult$p.value, W = testresult$statistic, n = length(plotVar))
#	})
#   ShapiroResult <- data.frame(do.call("rbind", ret))


#3. calulate
allResults <- list()
# iterate over all parameters and create plots for all of them
for (i in 1:length(selReadouts)) {
	#remove NA (shapiro test allows NA but data has to have 3 - 5000 non-missing-values)
	data <- kIn[which(!is.na(kIn[,selReadouts[i]])), selReadouts[i]]

    # if there are more than 5000 data points, run test on a subset
    if(length(data) > 5000) {
        data <- sample(data, 5000)
    }

    # do the test and add the p-value to the plot
	result <- shapiro.test(data)
	
	allResults[[i]] <- data.frame(parameter = selReadouts[i], "p-value" = result$p.value, "log10(p-value)" = log10(result$p.value), "p-value.text" = format(result$p.value, scientific = TRUE, digits = 4), W = result$statistic, n = length(data))
	}

rOut <- data.frame(do.call("rbind", allResults))

]]>
</rgg>

########################################################################################
# name: Normalization Carpenter
# author: Marc Bickle
# category: normalization

Normalizes using a projection of the cell based data between 0 and 1 based on the 1st percentile and the 99th percentile

######
<rgg>

<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>

<gaprow height="1"/>

<!-- 2. Configuration-->

<separator label="Options" span="full"/>
<gaprow height="2"/>

#1.0 Parameter selection
<group>
selReadouts = c(<panellistbox label="Parameters to normalize" items="$$$NUM_ATTRIBUTES$$$" span="full"/>)

Group = <combobox label="Group" items="$$$STR_ATTRIBUTES$$$" />;

Treatment = <combobox label="Treatment" items="$$$STR_ATTRIBUTES$$$" />;
</group>

<![CDATA[
#2.0 R code

#2.3. calulate
platelist<-unique(kIn[,Group])

Norm <- function(y) ((controlLow-y)/controlHigh)
final<-NULL

for(i in 1:length(platelist)){
	#DEBUG i<-"Week10_40111"
	data<-kIn[which(kIn[,Group] == platelist[i]),]
	controlPop<-data[which(data[,Treatment] == "DMSO"),]
	for(j in 1:length(selReadouts)){
		controlLow <- as.numeric(quantile(controlPop[,selReadouts[j]], probs= 0.01, type = 4))
		controlHigh <- as.numeric(quantile(controlPop[,selReadouts[j]], probs= 0.99, type = 4))
		res<-apply(as.array(data[,selReadouts[j]]), 1, Norm)
		resframe<-data.frame(res)
		names(resframe)<-paste(selReadouts[j], "norm", sep ="_")
		data<-cbind(data, resframe)
	}
	final<-rbind(final,data)
}

rOut <- final;

]]>
</rgg>
########################################################################################
# name: Correlation of parameters
# author: Martin Stoeter
# category: relations

Calculates the correlation between all chosen parameters.

For all selected parameters a pairwise correlation will be calculated (P1 vs P2, P1 vs P3, P2 vs P3) for the entire table (missing values will be removed/ignored).
n is the number of data pointe in correlation. The type of correlation can be selected.
######

<rgg>

<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->

<separator label="Options" span="full"/>
<gaprow height="2"/>

# 1. Parameter selection

<group>
# 1) select parameters for replicate correlation
paramName = c(<panellistbox label="Parameters for correlation" items="$$$NUM_ATTRIBUTES$$$" span="full"/>);

# 2) select correlation method
corrFunctionMethod = <combobox items="pearson, kendall, spearman" label="Select correlation method"/>;

</group>

<![CDATA[

#define replicates: e.g A,B,C
repVector <- paramName

#iterate all parameters(A,B,C -> AB, AC, BC)
for (i in 1:(length(repVector)-1)) {

	for (j in (i+1):length(repVector)) {

			corrTable <- as.matrix(kIn[,c(repVector[i], repVector[j])])
			#remove NA
			corrTable <- corrTable[which(!is.na(corrTable[,repVector[i]]) & !is.na(corrTable[,repVector[j]])),]

			#check if XYtable match is bigger than 1
			sampleIDmatch <- length(corrTable)

			if (sampleIDmatch > 1) {
				#calculate correlation
				correlation <- cor.test(corrTable[,repVector[i]], corrTable[,repVector[j]], method = corrFunctionMethod)
				corrEstimate <- correlation$"estimate"
				corrMethod <- correlation$"method"
				} else {
				corrEstimate <- as.numeric(NA)
				corrMethod <- "not enough samples for correlation"
				sampleIDmatch <- 0
				}

		#assemble result
		pearsonResult <- data.frame(parameter1 = repVector[i], parameter2 = repVector[j], n = sampleIDmatch, coefficient = corrEstimate, method = corrMethod)

		if (exists("pearsonResultTable")) {
			pearsonResultTable <- data.frame(rbind(pearsonResultTable, pearsonResult))
			} else {
			pearsonResultTable <- pearsonResult
			}
		}
	}

rOut <- pearsonResultTable
]]>

</rgg>
########################################################################################
# name: Correlation of multi-parametric profiles
# author: Martin Stoeter
# category: relations

Calculates the correlation between multi-parameteric profiles.

Select columns for "Group identifier" (e.g., gene symbol) and "Sample identifier" (e.g. siRNA-ID or oligo letter). Use the check boxes to define which combinations should be calculated. 
a) all combinations of groups: e.g. oligos of gene A will be correlated with oligos of gene B
b) all combinations of samples: e.g. oligo A will be correlated with oligo B
Be aware that if you do all combinations the snippet could take a while! 

For all pairwise combinations of the correlation of selected profile parameters will be calculated (missing values will be removed/ignored). 
n is the number of parameters in correlation. The type of correlation can be selected.
######

<rgg>

<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->

<separator label="Options" span="full"/>
<gaprow height="2"/>

# 1. Parameter selection

<group>
# 1) select parameters for replicate correlation
paramName = c(<panellistbox label="Parameters for profile" items="$$$NUM_ATTRIBUTES$$$" span="full"/>);

# 2) select column that contains sample ID
<hbox>
IDgene = <combobox label="Group identifier" items="$$$STR_ATTRIBUTES$$$" />
<checkbox label="All combinations of groups" var="allCombiGene" selected="false"/>
</hbox>

# 3) select column that contains group ID
<hbox>
IDoligo = <combobox label="Sample identifier" items="$$$STR_ATTRIBUTES$$$"/>
<checkbox label="All combinations of samples" var="allCombiOligo" selected="false"/>
</hbox>

# 4) select correlation method
corrFunctionMethod = <combobox items="pearson, kendall, spearman" label="Select correlation method"/>;

</group>

<![CDATA[

#define group: e.g genes
geneVector <- unique(kIn[, IDgene])

# create unqique combinations (disregarding order!) to calculate the correlation on
combVec <- t(rbind(geneVector,geneVector))

#define result table before iterations
pearsonResult <- as.data.frame(NULL)

#now do correlation within groups (geneA vs geneA)
for (comb in 1:length(combVec[,1])){
		# extract data rows to correlate
		kInXtable <- kIn[which(kIn[,IDgene] == combVec[comb,1]),c(IDgene, IDoligo, paramName)]
		kInYtable <- kIn[which(kIn[,IDgene] == combVec[comb,2]),c(IDgene, IDoligo, paramName)]
		#both for loops avoid correlation A vs A (same =1) and redundancy A vs B and B vs A (here necessary because groups are the same!) 
		for (xOligo in 1:(length(kInXtable[,1])-1)){
			for (yOligo in (xOligo+1):length(kInYtable[,1])){
				#correlate all olives or only the same olives (oligoA vs oligoA, B, ...)
				if (allCombiOligo || (kInXtable[xOligo,IDoligo] == kInYtable[yOligo,IDoligo])){	
					corrTable <- t(as.matrix(rbind(kInXtable[xOligo,paramName], kInYtable[yOligo,paramName])))
					#remove NA
					corrTable <- corrTable[which(!is.na(corrTable[,1]) & !is.na(corrTable[,2])),]
					sampleIDmatch <- length(corrTable[,1])
					if (sampleIDmatch > 1) {
						correlation <- cor.test(corrTable[,1], corrTable[,2], method = corrFunctionMethod)		
						corrEstimate <- correlation$"estimate"
						corrMethod <- correlation$"method"
						} else {
						corrEstimate <- as.numeric(NA)
						corrMethod <- "not enough values for correlation"
						sampleIDmatch <- as.numeric(NA)
						}
					pearsonResult <- rbind(pearsonResult, data.frame(groupID1 = combVec[comb,1], sampleID1 = kInXtable[xOligo,IDoligo], groupID2 = combVec[comb,2], sampleID1 = kInYtable[yOligo,IDoligo], n = sampleIDmatch, coefficient = corrEstimate, method = corrMethod))
					}
				}
			}
		}

#now do correlation between groups (geneA vs geneB)
if (allCombiGene){		
combVec <- t(combn(geneVector,2))
for (comb in 1:length(combVec[,1])){
		# extract data rows to correlate
		kInXtable <- kIn[which(kIn[,IDgene] == combVec[comb,1]),c(IDgene, IDoligo, paramName)]
		kInYtable <- kIn[which(kIn[,IDgene] == combVec[comb,2]),c(IDgene, IDoligo, paramName)]
		for (xOligo in 1:length(kInXtable)){
			for (yOligo in 1:length(kInYtable)){
				#correlate all olives or only the same olives (oligoA vs oligoA, B, ...)
				if (allCombiOligo || (kInXtable[xOligo,IDoligo] == kInYtable[yOligo,IDoligo])){	
					corrTable <- t(as.matrix(rbind(kInXtable[xOligo,paramName], kInYtable[yOligo,paramName])))
					#remove NA
					corrTable <- corrTable[which(!is.na(corrTable[,1]) & !is.na(corrTable[,2])),]
					sampleIDmatch <- length(corrTable[,1])
					if (sampleIDmatch > 1) {
						correlation <- cor.test(corrTable[,1], corrTable[,2], method = corrFunctionMethod)		
						corrEstimate <- correlation$"estimate"
						corrMethod <- correlation$"method"
						} else {
						corrEstimate <- as.numeric(NA)
						corrMethod <- "not enough values for correlation"
						sampleIDmatch <- as.numeric(NA)
						}
					#assemble result
					pearsonResult <- rbind(pearsonResult, data.frame(groupID1 = combVec[comb,1], sampleID1 = kInXtable[xOligo,IDoligo], groupID2 = combVec[comb,2], sampleID1 = kInYtable[yOligo,IDoligo], n = sampleIDmatch, coefficient = corrEstimate, method = corrMethod))
					}
				}
			}
		}
}

rOut <- pearsonResult
]]>

</rgg>
########################################################################################
# name: Correlation of replicates
# author: Martin Stoeter
# category: relations

Calculates the correlation between replicates for all chosen parameters.

The table must contain a column of replicate information. Then another column must contain the sample identifier, which must be unique within a replicate (e.g. platenumber::well, but not barcode!), AND the same between the replicates. 
For the corresponding sample identifiers the correlation will be calculated pairwise between the replicates (A vs B, A vs C, B vs C) for the selected parameters (missing values will be removed/ignored).
n is the number of sample identifiers per replicate in correlation. The type of correlation can be selected.

Trouble shooting:
a) "sampleID not unique" -> more than 1 sampleID (eg wells) per replicate
b) "not enough samples for correlation" -> sampleID for a replicate = 0 (no data to correlate)
HINT: use GroupBy[Unique concatenate with count(replicate)] on selected sampleID column, must be replicate count = 1 for each sampleID
######

<rgg>

<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->

<separator label="Options" span="full"/>
<gaprow height="2"/>

# 1. Parameter selection

<group>
# 1) select parameters for replicate correlation
paramName = c(<panellistbox label="Parameters for correlation" items="$$$NUM_ATTRIBUTES$$$" span="full"/>);

# 2) select column that contains replicate annotation
repColName = <combobox label="Replicate column" items="$$$STR_ATTRIBUTES$$$" default-value="replicate"/>;

# 3) select column that contains sample ID
IDname = <combobox label="Sample identifier" items="$$$STR_ATTRIBUTES$$$" />;

# 4) select correlation method
corrFunctionMethod = <combobox items="pearson, kendall, spearman" label="Select correlation method"/>;

</group>


<![CDATA[

#define replicates: e.g A,B,C
repVector <- unique(kIn[, repColName])

#iterate all replicates(A,B,C -> AB, AC, BC)
for (i in 1:(length(repVector)-1)) {

	#define first table (A): e.g. kInA <- kIn[(which(kIn$"replicate"=="A")),c("sampleID","replicate","AvgIntenCh1","MinDistCh1","AreaCh1","CellNumber")]
	kInXtable <- kIn[which(kIn[,repColName] == repVector[i]),c(IDname, repColName, paramName)]

	for (j in (i+1):length(repVector)) {

		#define second table (B)
		kInYtable <- kIn[which(kIn[,repColName] == repVector[j]),c(IDname, repColName, paramName)]

		for (paramIteration in paramName) {

		#check if sampleIDs are unique
		if (length(unique(kInXtable[,IDname])) == length(kInXtable[,IDname]) & length(unique(kInYtable[,IDname])) == length(kInYtable[,IDname])) {

			corrTable <- merge(kInXtable[,c(IDname, repColName, paramIteration)], kInYtable[,c(IDname, repColName, paramIteration)], by.x = IDname, by.y =IDname)
			#remove NA
			corrTable <- corrTable[which(!is.na(corrTable[,paste(paramIteration, "x", sep="."),]) & !is.na(corrTable[,paste(paramIteration, "y", sep="."),])),]

			#check if XYtable match is bigger than 1
			sampleIDmatch <- length(corrTable[,1])

			if (sampleIDmatch > 1) {				
				#calculate correlation
				correlation <- cor.test(corrTable[,paste(paramIteration, "x", sep=".")], corrTable[,paste(paramIteration, "y", sep=".")], method = corrFunctionMethod)
				corrEstimate <- correlation$"estimate"
				corrMethod <- correlation$"method"
				} else {
				corrEstimate <- as.numeric(NA)
				corrMethod <- "not enough samples for correlation"
				sampleIDmatch <- 0
				}
			} else {
			corrEstimate <- as.numeric(NA)
			corrMethod <- "sampleID not unique"
			sampleIDmatch <- as.numeric(NA)
			}

		#assemble result
		pearsonResult <- data.frame(parameter = paramIteration, replicate1 = repVector[i], replicate2 = repVector[j], n = sampleIDmatch, coefficient = corrEstimate, method = corrMethod)

		if (exists("pearsonResultTable")) {
			pearsonResultTable <- data.frame(rbind(pearsonResultTable, pearsonResult))
			} else {
			pearsonResultTable <- pearsonResult
			}
		}
		}
	}

rOut <- pearsonResultTable

]]>

</rgg>
########################################################################################
# name: Create column name table from selection
# author: Holger Brandl, Martin Stoeter
# category: utilities
# preview: CreateColumnNameTableFromSelection.png

Creates a table with a single column that contains the selected column headers.
- select or type name of column for column headers
- preview shows what the snippet is doing instead of using KNIME nodes

######

<rgg>

<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->

<separator label="Options" span="full"/>
<gaprow height="2"/>

#1.0 Parameter selection
<group>
# 1) select the columns
featSelection = match(c(<panellistbox label="Column selection" items="$$$PARNAMES$$$" visible-row-count="6" span="full"/>), names(kIn));

# 2) select column name
<textfield label="type column header" var="columnHeader" data-type="text" default-value= "column header" size="10" span="full"/>
</group>

<![CDATA[

#2.0 R code

#2.1 load libraries

#2.2.1 manage RGG to R: define as numbers

#2.2.2 manage RGG to R: set values to default and check values
if (is.na(columnHeader)) 	columnHeader <- "column header"	  #default

#2.3. calulate
rOut <- as.data.frame(c(names(kIn)[featSelection]));
names(rOut) <- columnHeader;

]]>

</rgg>
########################################################################################
# name: Handle and filter NaN and infinite values
# author: Martin Stoeter
# category: utilities

NaN are missing values that are created by some nodes (e.g. HCS tools - Normalization) and that are different from KNIMEs' missing values ("?", in R = "NA").
Infinite are positive or negative invinite values that are created by some nodes (e.g. HCS tools - Normalization) by devision by zero.
NaN can be filtered by Row Filter with patters "NaN" on number column, however this is tedious for many columns. 
Infinite can be filtered by Row Filter using very high or low values, however this is tedious for many columns.
This R snippet allows handling of NaN and infinite on input table.
- select type of output:
	1. All column names and number of found NaN and infinite (count all NaN and infinite per column)
	2a. Only column names that contain NaN (list of NaN columns)
	2b. Only column names that contain NaN or infinite (list of NaN and infinite columns)
	3a. Input table without NaN columns (filter NaN columns out)
	3b. Input table without NaN and infinite columns (filter NaN and infinite columns out)
	4a. Input table with NaN replaced by NA (NA = KNIME understandable missing values)
	4b. Input table with NaN and infinite replaced by NA (NA = KNIME understandable missing values)

######

<rgg>

<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->

<separator label="Options" span="full"/>
<gaprow height="1"/>

#1.0 Parameter selection
<group>

# 2) select column name
typeOfOutput = <combobox label="Select type of output" items="All column names and number of found NaN and infinite,Only column names that contain NaN,Only column names that contain NaN or infinite,Input table without NaN columns,Input table without NaN or infinite columns,Input table with NaN replaced by NA,Input table with NaN and infinite replaced by NA" />;
</group>

<![CDATA[

#2.0 R code

#2.1 load libraries

#2.2.1 manage RGG to R: define as numbers

#2.2.2 manage RGG to R: set values to default and check values

#2.3. calulate
NaNresult <- list()

for (i in 1:(length(kIn[1,]))) {
	NaNresult[[i]] <- data.frame(columnName=names(kIn[i]), numberOfNaN=length(which(is.nan(kIn[,i]))), numberOfInfinite=length(which(is.infinite(kIn[,i])))) 
		}

#returns the column names with the number of NaN found
NaNresult <- do.call("rbind",NaNresult)

#return the input table without column containing NaN
if (typeOfOutput == "Input table without NaN columns") {
	NaNresult <- kIn[,which(!NaNresult[,2]>0)]
	} 
	
#return the input table without column containing NaN or infinite
if (typeOfOutput == "Input table without NaN or infinite columns") {
	NaNresult <- kIn[,which((!NaNresult[,2]>0) | (!NaNresult[,3]>0))]
	} 

#returns only the column names that contain NaN values
if (typeOfOutput == "Only column names that contain NaN") {
	NaNresult <- NaNresult[which(NaNresult[,2]>0),]
	}
	
#returns only the column names that contain NaN or infinite values
if (typeOfOutput == "Only column names that contain NaN or infinite") {
	NaNresult <- NaNresult[which((NaNresult[,2]>0) | (NaNresult[,3]>0)),]
	}

#replace NaN with NA and turn complete table
if (typeOfOutput == "Input table with NaN replaced by NA") {
	for (i in 1:(length(kIn[1,]))) {
		if (NaNresult[i,"numberOfNaN"] > 0) {
			kIn[which(is.nan(kIn[,i])),i] <- NA
			}
		}
	NaNresult <- kIn
	}
	
#replace NaN and infinite with NA and turn complete table
if (typeOfOutput == "Input table with NaN and infinite replaced by NA") {
	for (i in 1:(length(kIn[1,]))) {
		if ((NaNresult[i,"numberOfNaN"] > 0) || (NaNresult[i,"numberOfInfinite"] > 0)) {
			kIn[which((is.nan(kIn[,i])) | (is.infinite(kIn[,i]))),i] <- NA
			}
		}
	NaNresult <- kIn
	}

rOut<- NaNresult

]]>
</rgg>
########################################################################################
# name: Reference Column Filter (2:1)
# author: Martin Stoeter
# category: utilities
# preview: ReferenceColumnFilter.png

Filters the unselected columns of input port 1 (columns to be filtered) using a reference column of input port 2.
- select columns to be kept in input 1 (filter is not applied)
- select the column in input 2 that contains column headers for reference filter
- select way of filtering (filter in = keep what is in reference, filter out = drop what is in reference)

Preview shows what the snippet is doing instead of using KNIME nodes

NEEDS R snippet (2:1) !!!
######

<rgg>

<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->

<separator label="Options" span="full"/>
<gaprow height="1"/>

#1.0 Parameter selection

<group>
# 1) select columns that should be kept
keepColumns = c(<panellistbox label="Select columns that are not filtered (input 1)" items="$$$PARNAMES$$$" span="full"/>);

# 2) select column that contains replicate annotation 
refColumnName = <combobox label="Column for reference filter (input 2)" items="$$$STR_ATTRIBUTES_2$$$" />;

# 3) type of filter 
filter = <combobox label="Way to filter" items="filter in,filter out" />;

</group>

<![CDATA[

#2.0 R code

#R code for debugging
#refColumnName <- "parameter"
#keepColumns <- colnames(kIn1[,1:18])
#end R code for debugging

#2.1 load libraries

#2.2.1 manage RGG to R: define as numbers

#2.2.2 manage RGG to R: set scales to default and check scales

#2.3. calulate
allColumns <- colnames(kIn1)
refColumn <- kIn2[,refColumnName]
if (filter == "filter in") {
	outputTable <- kIn1[,colnames(kIn1[,which((allColumns %in% keepColumns) | (allColumns %in% refColumn))])]
	} else {
	outputTable <- kIn1[,colnames(kIn1[,which((allColumns %in% keepColumns) | !(allColumns %in% refColumn))])]
	}
rOut <- outputTable
]]>

</rgg>
#######################################################################################
# name: Get info from R-server (installed packages, R version, system info)
# author: Martin Stoeter
# category: utilities
# preview: 

This snippet lists the version and packages installed on your R-server.
a) installed packages and their versions (installed.packages())
b) libraries/packages that can be loaded (library())
c) base packages (sessionInfo()["basePkgs"])
d) R version and platform (sessionInfo()[1])
e) other packages installed (not always present)
f) system information (Sys.info())
######

<rgg>
<!--1. Title and short description -->

<h3 text="$$$TEMPLATE_NAME$$$" aligment="center" span="full"/>
<separator label="Description" span="full"/>
<labelarea span="full">$$$TEMPLATE_DESC$$$</labelarea>
<gaprow height="1"/>

<!-- 2. Configuration-->
<separator label="Options" span="full"/>
<gaprow height="2"/>

#1.0 Parameter selection
<group>
# 1.1 select type of transformation
getInfo = <combobox items="installed_packages,libraries,base_packages,R_version,other_packages,system_info" label="Power transformation"/>

</group>

<![CDATA[

#2.0 R code
rOut <- switch(getInfo,
	installed_packages = as.data.frame(installed.packages()), libraries = as.data.frame(library()[2]), base_packages = as.data.frame(sessionInfo()["basePkgs"]), R_version = as.data.frame(sessionInfo()[1]), other_packages = as.data.frame(names(sessionInfo()["otherPkgs"][[1]])), system_info = as.data.frame(Sys.info()))

#rOut <- as.data.frame(installed.packages())
#rOut <- as.data.frame(library()[2])
#rOut <- as.data.frame(sessionInfo()["basePkgs"])
#rOut <- as.data.frame(sessionInfo()[1])
#rOut <- as.data.frame(names(sessionInfo()["otherPkgs"][[1]]))
#rOut <- as.data.frame(Sys.info())

]]>
</rgg>

########################################################################################
# name: Reshape to long format
# category: utilities

Creates a table with a single measurement column and several id columns.

######

library(reshape)
rOut <- melt(kIn)
